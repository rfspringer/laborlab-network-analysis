{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649cbfde-1dbc-44de-b4e4-f08a6c359353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipumspy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.3)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=6.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (6.0.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (4.12.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0,>=4.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (4.13.0)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.5.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (1.5.3)\n",
      "Requirement already satisfied: pyarrow<11.0.0,>=10.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (10.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.11.1->ipumspy) (2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from importlib-metadata<5.0.0,>=4.13.0->ipumspy) (3.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.2->ipumspy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.2->ipumspy) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.2->ipumspy) (1.26.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (2023.7.22)\n",
      "\u001b[33mWARNING: requests 2.31.0 does not provide the extra 'use-chardet-on-py3'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.5.2->ipumspy) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.10/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipumspy networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ddfe98b-3a7e-439b-8ba7-97a170cab74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from ipumspy import readers, ddi\n",
    "from itertools import combinations, groupby\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89ea31c3-423d-41c9-9ed8-2057cb5dda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_VARS = ['YEAR', 'SAMPLE', 'SERIAL', 'CBSERIAL', 'HHWT', 'CLUSTER', 'STRATA', 'GQ', 'PERNUM', 'PERWT'] \n",
    "WEALTH_PROXIES = ['INCINVST', 'INCBUS00']\n",
    "INCOMES = ['INCWAGE', 'INCBUS00', 'INCSS', 'INCWELFR', 'INCINVST', 'INCRETIR', 'INCSUPP', 'INCOTHER']\n",
    "\n",
    "def create_directory_with_timestamp(descriptor='graph'):\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    directory_name = f\"graphs/{descriptor}_{timestamp}\"\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "    return directory_name\n",
    "\n",
    "\n",
    "def add_to_data_graph(df, graph, industry_state_dict):\n",
    "    nodes = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['AGE'] >= 15:    #otherwise lots of n/a values\n",
    "            node_id = str(row['SERIAL']) + '-' + str(row['PERNUM'])\n",
    "            industry_state = str(row['STATEICP']) + '-' + str(row['IND'])\n",
    "            wealth_proxy = row[WEALTH_PROXIES].sum()\n",
    "            node_attributes = row.drop(DEFAULT_VARS).to_dict()\n",
    "            node_attributes['wealth_proxy'] = wealth_proxy\n",
    "            node_attributes['state_x_industry'] = industry_state\n",
    "\n",
    "            nodes.append((node_id, node_attributes))\n",
    "            industry_state_dict[industry_state].append(node_id)\n",
    "\n",
    "    graph.add_nodes_from(nodes)\n",
    "    return graph, industry_state_dict\n",
    "\n",
    "\n",
    "def process_data(iterator, dir, save=False):\n",
    "    print(\"Processing IPUMS data (might take a while)\\n\")\n",
    "    nodes_graph = nx.DiGraph()\n",
    "    industry_state_dict = defaultdict(list)\n",
    "    i = 0\n",
    "    for df_chunk in iterator: \n",
    "        print(f\"\\rProcessed: {i * 1000}\", end='', flush=True)\n",
    "        nodes_graph, nodes_industry_state_dict = add_to_data_graph(df_chunk, nodes_graph, industry_state_dict)\n",
    "        i += 1\n",
    "\n",
    "    print()\n",
    "    \n",
    "    if save:\n",
    "        print(\"Saving results...\")\n",
    "\n",
    "        filename = os.path.join(dir, \"nodes_graph.pkl\")\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(nodes_graph, f)\n",
    "\n",
    "        dict_filename = os.path.join(dir, \"industry_state_dict.pkl\")\n",
    "        with open(dict_filename, 'wb') as f:\n",
    "            pickle.dump(nodes_industry_state_dict, f)\n",
    "\n",
    "    return nodes_graph, nodes_industry_state_dict\n",
    "\n",
    "\n",
    "def collect_edges(graph, industry_state_dict, incl_weight_if_0 = False):\n",
    "    edges_dict = defaultdict(list)\n",
    "    total_industries = len(industry_state_dict)\n",
    "    count = 1\n",
    "\n",
    "    for industry_x_state, nodes in industry_state_dict.items():\n",
    "        print(f\"\\rCollecting edges: {count}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        if len(nodes) > 1:\n",
    "            nodes_data = [(node, graph.nodes[node]['wealth_proxy']) for node in nodes]\n",
    "            nodes_data.sort(key=lambda x: x[1], reverse=True)\n",
    "            for i in range(len(nodes_data) - 1):\n",
    "                u, wealth_u = nodes_data[i]\n",
    "                for j in range(i + 1, len(nodes_data)):\n",
    "                    v, wealth_v = nodes_data[j]\n",
    "                    weight = wealth_u - wealth_v\n",
    "\n",
    "                    if weight != 0 or incl_weight_if_0:\n",
    "                        edges_dict[industry_x_state].append((u, v, weight))\n",
    "        count += 1\n",
    "    print()\n",
    "    return edges_dict\n",
    "\n",
    "def construct_graph(nodes_graph, edges_dict):\n",
    "    big_graph = nodes_graph\n",
    "    total_industries = len(edges_dict)\n",
    "    count = 0\n",
    "\n",
    "    for industry_x_state, edges in edges_dict.items():\n",
    "        print(f\"\\rConstructing big graph: {count}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        count += 1\n",
    "        if len(edges) > 1:\n",
    "            big_graph.add_weighted_edges_from(edges)\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "    return big_graph\n",
    "\n",
    "\n",
    "def process_industry(industry_x_state, nodes, graph, incl_weight_if_0):\n",
    "    nodes_data = np.array([(node, float(graph.nodes[node]['wealth_proxy'])) for node in nodes])\n",
    "    if len(nodes_data) > 1:\n",
    "        nodes_data = nodes_data[nodes_data[:, 1].argsort()[::-1]]  # Ensure sorting by float values\n",
    "        for (u, wealth_u), (v, wealth_v) in combinations(nodes_data, 2):\n",
    "            weight = float(wealth_u) - float(wealth_v)\n",
    "            if weight != 0 or incl_weight_if_0:\n",
    "                yield (industry_x_state, u, v, weight)\n",
    "\n",
    "def collect_edges_to_generator(graph, industry_state_dict, incl_weight_if_0=False):\n",
    "    total_industries = len(industry_state_dict)\n",
    "    for i, (industry_x_state, nodes) in enumerate(industry_state_dict.items(), 1):\n",
    "        print(f\"\\rCollecting edges: {i}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        yield from process_industry(industry_x_state, nodes, graph, incl_weight_if_0)\n",
    "    print()\n",
    "\n",
    "def construct_graph_from_generator(nodes_graph, edges_generator):\n",
    "    big_graph = nodes_graph.copy()  # Create a copy to avoid modifying the original graph\n",
    "    \n",
    "    # Group edges by industry_x_state\n",
    "    sorted_edges = sorted(edges_generator, key=itemgetter(0))\n",
    "    grouped_edges = groupby(sorted_edges, key=itemgetter(0))\n",
    "    \n",
    "    total_industries = sum(1 for _ in grouped_edges)  # Count the number of industries\n",
    "    \n",
    "    # Reset the groupby object\n",
    "    grouped_edges = groupby(sorted_edges, key=itemgetter(0))\n",
    "    \n",
    "    for count, (industry_x_state, industry_edges) in enumerate(grouped_edges, 1):\n",
    "        print(f\"\\rConstructing big graph: {count}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        edges = [(u, v, weight) for _, u, v, weight in industry_edges]\n",
    "        if len(edges) > 1:\n",
    "            big_graph.add_weighted_edges_from(edges)\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "def construct_graphs(industry_state_dict, edge_dict, dir, batch_size=10):\n",
    "    total_industries = len(edge_dict)\n",
    "    count = 0\n",
    "\n",
    "    subgraphs_to_save = []\n",
    "    for industry_x_state, edges in edge_dict.items():\n",
    "        print(f\"\\rConstructing graphs: {count}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        print(len(edges))\n",
    "        print(edges[0])\n",
    "        count += 1\n",
    "        if len(edges) > 1:\n",
    "            nodes = industry_state_dict[industry_x_state]\n",
    "\n",
    "            # Create a new DiGraph for each subgraph\n",
    "            subgraph = nx.DiGraph()\n",
    "            subgraph.add_nodes_from(nodes)\n",
    "            subgraph.add_weighted_edges_from(edges)\n",
    "            subgraphs_to_save.append((subgraph, industry_x_state))\n",
    "\n",
    "            # Save subgraphs in batches\n",
    "            if count % batch_size == 0 or count == total_industries:\n",
    "                save_subgraphs(subgraphs_to_save, dir)\n",
    "                subgraphs_to_save = []  # Reset batch\n",
    "    print(\"\\nDone!\")\n",
    "    return big_graph\n",
    "\n",
    "\n",
    "def save_subgraphs(subgraphs_to_save, dir):\n",
    "    for subgraph, industry_x_state in subgraphs_to_save:\n",
    "        filename = os.path.join(dir, industry_x_state + '.pkl')\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(subgraph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94906076-a9c5-43c3-9e91-74425de0aea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198350f-8e31-43cf-b650-f2b3d91c89ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "462200a5-9000-49ca-8376-24de31006491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARSE IPUMS DATASET FOR NODES AND INDUSTRY X STATE MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ffce2e2-3171-4050-9079-fa47f9116c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up IPUMS Readers\n",
      "Processing IPUMS data (this might take a while)\n",
      "\n",
      "Processed: 3373000\n",
      "Saving results...\n",
      "Saved nodes graph and nodes/industryXstate map to graphs/full_graph_2024-06-26_11-58-48\n"
     ]
    }
   ],
   "source": [
    "ddi_codebook = readers.read_ipums_ddi('data/ipums_codebook.xml')\n",
    "iter_microdata = readers.read_microdata_chunked(ddi_codebook, 'data/ipums.dat.gz', chunksize=1000)\n",
    "print(\"Set up IPUMS Readers\")\n",
    "\n",
    "dir = create_directory_with_timestamp('full_graph')\n",
    "nodes_graph, nodes_industry_state_dict = process_data(iter_microdata, dir, save=True)\n",
    "print(f\"Saved nodes graph and nodes/industryXstate map to {dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4081af-7ddd-488c-b78b-1010ba1c2854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8203fd-e2ac-4492-ba07-9ec41ab3fe85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a94075-2d84-4035-b930-fa938f57824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD AND COLLECT ALL EDGES (usually infeasible bc of size of dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be188e5-d89a-4b04-a31e-89097f37ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{dir}/nodes_graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    nodes_graph = pickle.load(f)\n",
    "\n",
    "filename = f\"{dir}/nodes_dict.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    nodes_industry_state_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a71e65f-e7e6-4a0e-a9ab-9aaa5494bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges: 1/13044 industry x states processed"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m edges \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_industry_state_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 69\u001b[0m, in \u001b[0;36mcollect_edges\u001b[0;34m(graph, industry_state_dict, incl_weight_if_0)\u001b[0m\n\u001b[1;32m     66\u001b[0m             v, wealth_v \u001b[38;5;241m=\u001b[39m nodes_data[j]\n\u001b[1;32m     67\u001b[0m             weight \u001b[38;5;241m=\u001b[39m wealth_u \u001b[38;5;241m-\u001b[39m wealth_v\n\u001b[0;32m---> 69\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m incl_weight_if_0:\n\u001b[1;32m     70\u001b[0m                 edges_dict[industry_x_state]\u001b[38;5;241m.\u001b[39mappend((u, v, weight))\n\u001b[1;32m     71\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "edges = collect_edges(nodes_graph, nodes_industry_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7899f96-5422-415a-85fe-61efce28424d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bca958-8ad4-4bda-8061-4cbc009761f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02437bdc-fd5d-4183-83a5-4aee756687db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SUBSAMPLE 1% OF NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fda499e-fb35-4129-b807-d98afab8d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_nodes(nodes_graph, nodes_industry_state_dict, sample_fraction=0.01):\n",
    "    print(f\"Subsampling {sample_fraction * 100}% of nodes from the graph...\")\n",
    "    all_nodes = list(nodes_graph.nodes)\n",
    "    \n",
    "    # Subsample 1% of nodes\n",
    "    sample_size = int(len(all_nodes) * sample_fraction)\n",
    "    print(f\"Total nodes: {len(all_nodes)}, Sample size: {sample_size}\")\n",
    "    sampled_nodes = set(random.sample(all_nodes, sample_size))\n",
    "    subsampled_graph = nodes_graph.subgraph(sampled_nodes).copy()\n",
    "    print(\"Subsampling nodes completed.\")\n",
    "\n",
    "    # Create new industry_state_dict with subsampled nodes\n",
    "    print(\"Creating new industry_state_dict with subsampled nodes...\")\n",
    "    subsampled_industry_state_dict = defaultdict(list)\n",
    "    for industry_state, nodes in nodes_industry_state_dict.items():\n",
    "        subsampled_nodes_in_state = [node for node in nodes if node in sampled_nodes]\n",
    "        if subsampled_nodes_in_state:\n",
    "            subsampled_industry_state_dict[industry_state].extend(subsampled_nodes_in_state)\n",
    "    print(\"New industry_state_dict creation completed.\")\n",
    "\n",
    "    return subsampled_graph, subsampled_industry_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4058fe5-9851-4b82-a0db-c766f4da6f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampling 1.0% of nodes from the graph...\n",
      "Total nodes: 3373378, Sample size: 33733\n",
      "Subsampling nodes completed.\n",
      "Creating new industry_state_dict with subsampled nodes...\n",
      "New industry_state_dict creation completed.\n"
     ]
    }
   ],
   "source": [
    "subnodes, subdict = subsample_nodes(nodes_graph, nodes_industry_state_dict)\n",
    "\n",
    "subsample_dir = \"graphs/subsample_1percent\"\n",
    "\n",
    "filename = os.path.join(subsample_dir, \"nodes_graph.pkl\")\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(subnodes, f)\n",
    "\n",
    "filename = os.path.join(subsample_dir, \"nodes_dict.pkl\")\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(subdict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5171f630-5764-4291-922b-707428d716ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_dir = \"graphs/subsample_1percent\"\n",
    "\n",
    "filename = \"graphs/subsample_1percent/nodes_graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    subnodes = pickle.load(f)\n",
    "\n",
    "filename = \"graphs/subsample_1percent/nodes_dict.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    subdict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e069d16-4921-491e-8e07-c33fdd2c85a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges: 3000/5270 industry x states processed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges_dict = collect_edges(subnodes, subdict)\n",
    "\n",
    "print(\"saving edges industryXstate map\")\n",
    "filename = os.path.join(subsample_dir, 'edges_dict.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(edges_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "620235e3-9b7a-4dff-96ec-2e4d79f2bf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing big graph: 1521/1522 industry x states processed\n",
      "Done!\n",
      "saving graph\n"
     ]
    }
   ],
   "source": [
    "graph = construct_graph(subnodes, edges_dict)\n",
    "\n",
    "print(\"Saving graph\")\n",
    "filename = os.path.join(subsample_dir, 'graph.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dd20ad-74c4-49c1-93af-d0e13d185055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69b46aa-7c55-4667-9d3d-9d9ca62566b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"graphs/subsample_1percent/graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    nodes_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8012e2c-f3bd-475b-ade2-eee39d112453",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('graphs/subsample_1percent/graph.pkl', 'wb') as file:\n",
    "    pickle.dump(nodes_graph, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f675815-5ede-4e14-8c96-c5472c41198e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231149fa-7fd8-4bdc-a32e-5af19b92cf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae2ad9-afa3-4818-90e2-fb3371e4dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SUBSAMPLE FOR ILLINOIS (still too big to be able to process for me so far("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f38a90ce-17b0-45eb-b467-45612ac657e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_nodes_by_state(nodes_graph, nodes_industry_state_dict, icp=21):\n",
    "    # Identify nodes with matching STATEICP (default of 21 is the default state)\n",
    "    state_nodes = [node for node, data in nodes_graph.nodes(data=True) if data.get('STATEICP') == icp]\n",
    "    print(f\"Found {len(state_nodes)} nodes with STATEICP matching {icp}\")\n",
    "\n",
    "\n",
    "    # Create a subgraph with only state nodes\n",
    "    subsampled_graph = nodes_graph.subgraph(state_nodes).copy()\n",
    "    total_industries = len(nodes_industry_state_dict)\n",
    "    count = 0\n",
    "    print(\"Created subgraph with state nodes\")\n",
    "    \n",
    "    # Create new industry_state_dict with subsampled nodes\n",
    "    subsampled_industry_state_dict = {\n",
    "        industry_state: nodes for industry_state, nodes in nodes_industry_state_dict.items()\n",
    "        if industry_state.startswith(str(icp) + \"-\")\n",
    "    }\n",
    "\n",
    "    print(\"Created industry_state_dict with subsampled nodes\")\n",
    "    return subsampled_graph, subsampled_industry_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5fe20f0-5f67-46e3-880a-c04f6c08628b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsample_nodes_by_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# subsample nodes graph and nodes industry X state dict\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m subnodes, subdict \u001b[38;5;241m=\u001b[39m \u001b[43msubsample_nodes_by_state\u001b[49m(nodes_graph, nodes_industry_state_dict, icp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m21\u001b[39m)\n\u001b[1;32m      4\u001b[0m subsample_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraphs/subsample_illinois\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving nodes graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subsample_nodes_by_state' is not defined"
     ]
    }
   ],
   "source": [
    "# subsample nodes graph and nodes industry X state dict\n",
    "subnodes, subdict = subsample_nodes_by_state(nodes_graph, nodes_industry_state_dict, icp=21)\n",
    "\n",
    "subsample_dir = \"graphs/subsample_illinois\"\n",
    "\n",
    "print(\"saving nodes graph\")\n",
    "filename = os.path.join(subsample_dir, \"nodes_graph.pkl\")\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(subnodes, f)\n",
    "\n",
    "print(\"saving nodes industry x state dictionary\")\n",
    "filename = os.path.join(subsample_dir, \"nodes_dict.pkl\")\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(subdict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c512c5a-e918-4ca9-a4cc-01377ad47589",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_dir = \"graphs/subsample_illinois\"\n",
    "filename = \"graphs/subsample_illinois/nodes_graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    subnodes = pickle.load(f)\n",
    "\n",
    "filename = \"graphs/subsample_illinois/nodes_dict.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    subdict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331018b-cf11-4bd2-8ba3-b3cc56702f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges: 1/270 industry x states processed"
     ]
    }
   ],
   "source": [
    "edges = collect_edges_to_generator(subnodes, subdict)\n",
    "graph = construct_graph_from_generator(subnodes, edges)\n",
    "\n",
    "print(\"saving graph\")\n",
    "filename = os.path.join(subsample_dir, 'graph.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(graph, f)\n",
    "\n",
    "# print(\"saving edges industryXstate map\")\n",
    "# filename = os.path.join(subsample_dir, 'edges_dict.pkl')\n",
    "# with open(filename, 'wb') as f:\n",
    "#     pickle.dump(edges_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcfce932-2558-4226-89b9-644302feb556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-3:\n",
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A child process terminated abruptly, the process pool is not usable anymore",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_graph_from_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medges_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subsample_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 118\u001b[0m, in \u001b[0;36mconstruct_graph_from_generator\u001b[0;34m(nodes_graph, edges_generator)\u001b[0m\n\u001b[1;32m    115\u001b[0m big_graph \u001b[38;5;241m=\u001b[39m nodes_graph\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# Create a copy to avoid modifying the original graph\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Sort the generator by industry_x_state\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m sorted_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medges_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitemgetter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Group edges by industry_x_state\u001b[39;00m\n\u001b[1;32m    121\u001b[0m grouped_edges \u001b[38;5;241m=\u001b[39m groupby(sorted_edges, key\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;241m0\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m, in \u001b[0;36mcollect_edges_to_generator\u001b[0;34m(graph, industry_state_dict, incl_weight_if_0)\u001b[0m\n\u001b[1;32m    101\u001b[0m total_industries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(industry_state_dict)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m--> 104\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(process_industry, industry_x_state, nodes) \n\u001b[1;32m    105\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m industry_x_state, nodes \u001b[38;5;129;01min\u001b[39;00m industry_state_dict\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(futures, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mCollecting edges: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_industries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m industry x states processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    101\u001b[0m total_industries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(industry_state_dict)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m--> 104\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_industry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindustry_x_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    105\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m industry_x_state, nodes \u001b[38;5;129;01min\u001b[39;00m industry_state_dict\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(futures, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mCollecting edges: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_industries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m industry x states processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py:689\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_lock:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken:\n\u001b[0;32m--> 689\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BrokenProcessPool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken)\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_thread:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore"
     ]
    }
   ],
   "source": [
    "edges_dict = collect_edges_to_generator(subnodes, subdict)\n",
    "graph = construct_graph_from_generator(subnodes, edges_dict)\n",
    "\n",
    "print(\"saving graph\")\n",
    "filename = os.path.join(subsample_dir, 'graph.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7ee9720-50b0-47dd-9886-49037f25a54d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medges_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6adf67a-4298-48a0-92b8-65e52fb8737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"graphs/subsample_illinois/graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b96070b3-cfb1-4bc9-936d-eba597f42541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b6d17-c05d-4df0-b4df-7180781d75f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13510b64-034a-4746-928e-28cae49d21e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26073036-9e73-43d8-8958-6ba957459d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19947cae-2abc-4914-bef8-aac6cc6b0a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving edges industryXstate map\n"
     ]
    }
   ],
   "source": [
    "# build edges dict from subsample\n",
    "edges_dict = collect_edges(subnodes, subdict)\n",
    "\n",
    "print(\"saving edges industryXstate map\")\n",
    "filename = os.path.join(subsample_dir, 'edges_dict.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(edges_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30639f-1f3f-416a-b986-21f684c5e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "graph = construct_graph(subnodes, edges_dict)\n",
    "\n",
    "print(\"saving graph\")\n",
    "filename = os.path.join(subsample_dir, 'graph.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ee8a4-3678-4cab-8511-17428ced770b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502105f-9f3c-439e-946b-6200095538cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6e92c-ed2e-45bc-a972-7211f7b1c8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a85431-64ea-42bc-ade5-cdbaeb82f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges: 460/13044 industry x states processed"
     ]
    }
   ],
   "source": [
    "edges_dict = collect_edges(nodes_graph, nodes_industry_state_dict)\n",
    "\n",
    "print(\"saving edges industryXstate map\")\n",
    "filename = os.path.join(dir, 'edges_dict.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(edges_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acff293-dda1-4b80-b72c-fdc091f79a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28100dd-85d9-4cc9-8b55-79980c30a155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9de6e8-302b-4e58-af69-856d87c1e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RANDOM TESTING STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba8eb83-81ef-45e2-8766-fd679b377b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes_industry_state_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89451281-273f-4fb6-a395-d4ceeadeb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(nodes)for nodes in nodes_industry_state_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b097c7f7-6a6e-475b-b78e-f57b8d160c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01964725-512d-4ad2-8d2b-9974935e8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67018723"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417792f1-7332-4a41-bcfa-064f643c2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_zero_weight_edges(graph):\n",
    "    non_zero_edges = []\n",
    "    for u, v, data in graph.edges(data=True):\n",
    "        if data.get('weight', 0) != 0:\n",
    "            non_zero_edges.append((u, v, data['weight']))\n",
    "    return non_zero_edges\n",
    "\n",
    "# Example usage\n",
    "non_zero_edges = find_non_zero_weight_edges(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61dab7c4-2b4a-4649-a9a7-0ce32e383e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5232078205966413"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_zero_edges)/graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa43f97-e33c-4624-a65f-a6ad9b02d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one at a time stuff\n",
    "graph = nx.DiGraph()\n",
    "industry_state_dict = defaultdict(list)\n",
    "graph, industry_state_dict = add_to_data_graph(first_chunk, graph, industry_state_dict)\n",
    "graph = add_edges(graph, industry_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2ff700-955a-41b2-b8ff-a90de50510ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEICP</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>HHINCOME</th>\n",
       "      <th>...</th>\n",
       "      <th>FTOTINC</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCBUS00</th>\n",
       "      <th>INCSS</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>INCRETIR</th>\n",
       "      <th>INCSUPP</th>\n",
       "      <th>INCOTHER</th>\n",
       "      <th>INCEARN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>2022010000031</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2022000000011</td>\n",
       "      <td>41</td>\n",
       "      <td>280301</td>\n",
       "      <td>3</td>\n",
       "      <td>9999999</td>\n",
       "      <td>...</td>\n",
       "      <td>9999999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>202201</td>\n",
       "      <td>2</td>\n",
       "      <td>2022010000111</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022000000021</td>\n",
       "      <td>41</td>\n",
       "      <td>200001</td>\n",
       "      <td>3</td>\n",
       "      <td>9999999</td>\n",
       "      <td>...</td>\n",
       "      <td>9999999</td>\n",
       "      <td>12500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>202201</td>\n",
       "      <td>3</td>\n",
       "      <td>2022010000200</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2022000000031</td>\n",
       "      <td>41</td>\n",
       "      <td>280301</td>\n",
       "      <td>3</td>\n",
       "      <td>9999999</td>\n",
       "      <td>...</td>\n",
       "      <td>9999999</td>\n",
       "      <td>16400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>202201</td>\n",
       "      <td>4</td>\n",
       "      <td>2022010000261</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022000000041</td>\n",
       "      <td>41</td>\n",
       "      <td>110001</td>\n",
       "      <td>4</td>\n",
       "      <td>9999999</td>\n",
       "      <td>...</td>\n",
       "      <td>9999999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>202201</td>\n",
       "      <td>5</td>\n",
       "      <td>2022010000296</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2022000000051</td>\n",
       "      <td>41</td>\n",
       "      <td>150201</td>\n",
       "      <td>3</td>\n",
       "      <td>9999999</td>\n",
       "      <td>...</td>\n",
       "      <td>9999999</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  SAMPLE  SERIAL       CBSERIAL  HHWT        CLUSTER  STATEICP  STRATA  \\\n",
       "0  2022  202201       1  2022010000031  69.0  2022000000011        41  280301   \n",
       "1  2022  202201       2  2022010000111  22.0  2022000000021        41  200001   \n",
       "2  2022  202201       3  2022010000200  45.0  2022000000031        41  280301   \n",
       "3  2022  202201       4  2022010000261   4.0  2022000000041        41  110001   \n",
       "4  2022  202201       5  2022010000296  47.0  2022000000051        41  150201   \n",
       "\n",
       "   GQ  HHINCOME  ...  FTOTINC  INCWAGE  INCBUS00  INCSS  INCWELFR  INCINVST  \\\n",
       "0   3   9999999  ...  9999999        0         0  18800         0         0   \n",
       "1   3   9999999  ...  9999999    12500         0      0         0         0   \n",
       "2   3   9999999  ...  9999999    16400         0      0         0         0   \n",
       "3   4   9999999  ...  9999999        0         0   8600         0         0   \n",
       "4   3   9999999  ...  9999999        0      5000      0         0         0   \n",
       "\n",
       "   INCRETIR  INCSUPP  INCOTHER  INCEARN  \n",
       "0         0        0         0        0  \n",
       "1         0        0         0    12500  \n",
       "2         0        0         0    16400  \n",
       "3         0        0         0        0  \n",
       "4         0        0         0     5000  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chunk = next(iter_microdata)\n",
    "first_chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b206d968-aade-4136-95a2-bf74b5c303e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEICP</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>HHINCOME</th>\n",
       "      <th>...</th>\n",
       "      <th>FTOTINC</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCBUS00</th>\n",
       "      <th>INCSS</th>\n",
       "      <th>INCWELFR</th>\n",
       "      <th>INCINVST</th>\n",
       "      <th>INCRETIR</th>\n",
       "      <th>INCSUPP</th>\n",
       "      <th>INCOTHER</th>\n",
       "      <th>INCEARN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2022</td>\n",
       "      <td>202201</td>\n",
       "      <td>215</td>\n",
       "      <td>2022010011646</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022000002151</td>\n",
       "      <td>41</td>\n",
       "      <td>40301</td>\n",
       "      <td>3</td>\n",
       "      <td>9999999</td>\n",
       "      <td>...</td>\n",
       "      <td>9999999</td>\n",
       "      <td>999999</td>\n",
       "      <td>999999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>999999</td>\n",
       "      <td>999999</td>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR  SAMPLE  SERIAL       CBSERIAL  HHWT        CLUSTER  STATEICP  \\\n",
       "214  2022  202201     215  2022010011646  15.0  2022000002151        41   \n",
       "\n",
       "     STRATA  GQ  HHINCOME  ...  FTOTINC  INCWAGE  INCBUS00  INCSS  INCWELFR  \\\n",
       "214   40301   3   9999999  ...  9999999   999999    999999  99999     99999   \n",
       "\n",
       "     INCINVST  INCRETIR  INCSUPP  INCOTHER  INCEARN  \n",
       "214    999999    999999    99999     99999        0  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chunk[first_chunk['SERIAL'] == 215]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecdf1ed8-82c6-4278-a243-47ff084b6525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'SAMPLE', 'SERIAL', 'CBSERIAL', 'HHWT', 'CLUSTER', 'STATEICP',\n",
       "       'STRATA', 'GQ', 'HHINCOME', 'PERNUM', 'PERWT', 'SEX', 'AGE', 'MARST',\n",
       "       'RACE', 'RACED', 'EDUC', 'EDUCD', 'EMPSTAT', 'EMPSTATD', 'OCC', 'IND',\n",
       "       'INCTOT', 'FTOTINC', 'INCWAGE', 'INCBUS00', 'INCSS', 'INCWELFR',\n",
       "       'INCINVST', 'INCRETIR', 'INCSUPP', 'INCOTHER', 'INCEARN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chunk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3d5c7-d125-4fc1-a1a1-4ab218cf7e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
