{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "649cbfde-1dbc-44de-b4e4-f08a6c359353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipumspy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.3)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=6.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (6.0.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (4.12.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0,>=4.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (4.13.0)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.5.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (1.5.3)\n",
      "Requirement already satisfied: pyarrow<11.0.0,>=10.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipumspy) (10.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.11.1->ipumspy) (2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from importlib-metadata<5.0.0,>=4.13.0->ipumspy) (3.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.2->ipumspy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.2->ipumspy) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.2->ipumspy) (1.26.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->requests[use-chardet-on-py3]<3.0.0,>=2.26.0->ipumspy) (2023.7.22)\n",
      "\u001b[33mWARNING: requests 2.31.0 does not provide the extra 'use-chardet-on-py3'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.5.2->ipumspy) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.10/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipumspy networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ddfe98b-3a7e-439b-8ba7-97a170cab74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from ipumspy import readers, ddi\n",
    "from itertools import combinations, groupby\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a3c47-0a00-46ff-b7f9-e6cf1e55c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEALTH_PROXIES = ['INCBUS', 'INCFARM', 'INCIDR']\n",
    "LABOR_INCOME_VARS = ['INCWAGE', 'OINCBUS', 'OINCFARM']\n",
    "CAPITAL_INCOME_VARS = ['INCINT', 'INCCAPG', 'INCRENT']\n",
    "CAPITAL_GAINS_RATIOS = ['']\n",
    "# interest: INCINT                       \n",
    "# dividends: INCDIVID\n",
    "\n",
    "\n",
    "\n",
    "# rent: INCRENT\n",
    "# labor income: net self employment + wage and salary income (INCWAGE + OINCBUS)\n",
    "# labor + transfer income- inc tot - the wealth proxies?\n",
    "# cant find housing stuff? something with capgain variable that would be useful?\n",
    "#and sending the link\n",
    "\n",
    "                        \n",
    "# other things to try including:\n",
    "# INCCAPG: the amount of capital gains the respondent earned from shares of stock or mutual funds for those age 15 and older who received dividend income during the previous year.\n",
    "# INCFARM: farm income\n",
    "# INCBUS: non-farm business income\n",
    "# INCDRT: dividens, rent, royalties, income form estates  + trusts (substrat dividends to get rent royalties, estates, trusts\n",
    "# capital income: interest income; dividends; and rents, royalties, and income from estates or trusts INCDRT + INCINT -- could add incbus and incfarm too?\n",
    "\n",
    "\n",
    "\n",
    "#CPI99 to adjust income stuff\n",
    "\n",
    "# trimming top 1%??\n",
    "# adjustment factor for capital income? \"Given the large under reporting of capital income, we adjust up\n",
    "# reported capital income to match the NIPA figures. The adjustment factors we use are the inverse\n",
    "# of under reporting ratios reported in Rothbaum (2015a) for 2007-12: 1/.675 for interest income,\n",
    "# 1/.695 for dividends, and 1/.274 for rents, royalties, and income from estates or trusts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# prior to 1988, the Census Bureau asked only for total earnings over the\n",
    "#prior calendar year. Starting in 1988, separate questions were introduced for earnings on the\n",
    "# main job held in the previous year and other jobs, when applicable.\n",
    "#census rank proximity swap for top income pre 2011\n",
    "\n",
    "#swap values provided from 1994-2010, post 2010 used rank proximity swapping twhere above top code swapped with close and rounded off\n",
    "                        # swap values provied 1976-1995 too?\n",
    "\n",
    "#pareto imputation and topcode adjustment for pre 1986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f36cd-abdd-4817-b4be-0d9235bdff81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fc00a-bda5-4e2b-9a90-64a5b2d59a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6fc9a-023f-46b8-9c0f-8d456361379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap values for 1976- 2010\n",
    "# note that its different before 1988 because of the separate jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03129dd1-6d1f-4112-a5d0-2d6cfb33342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_with_timestamp(descriptor='dictionary'):\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    directory_name = f\"graphs/{descriptor}_{timestamp}\"\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "    return directory_name\n",
    "\n",
    "\n",
    "def add_to_data_graph(df, industry_state_dict):\n",
    "    nodes = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['AGE'] >= 18:    # filter by age above 18\n",
    "            id = str(row['SERIAL']) + '-' + str(row['PERNUM'])\n",
    "            state_industry = str(row['STATEICP']) + '-' + str(row['IND'])\n",
    "            wealth_proxy = row[WEALTH_PROXIES].sum() if (row[w] < 999999 for w in WEALTH_PROXIES) else None # filter out unknown and n/a\n",
    "            income = row['INCTOT'] if row['INCTOT'] < 9999998 else None    # filter out N/A and Unknown entries\n",
    "    \n",
    "            entry = {'stateXindustry': state_industry, 'id': id, 'wealth': wealth_proxy, 'income': income}\n",
    "            industry_state_dict[state_industry].append(entry)\n",
    "\n",
    "    return industry_state_dict\n",
    "\n",
    "\n",
    "def process_data(iterator, dir, save=False):\n",
    "    print(\"Processing IPUMS data (might take a while)\\n\")\n",
    "    nodes_graph = nx.DiGraph()\n",
    "    industry_state_dict = defaultdict(list)\n",
    "    i = 0\n",
    "    for df_chunk in iterator: \n",
    "        print(f\"\\rProcessed: {i * 1000}\", end='', flush=True)\n",
    "        industry_state_dict = add_to_data_graph(df_chunk, industry_state_dict)\n",
    "        i += 1\n",
    "\n",
    "    print()\n",
    "    \n",
    "    if save:\n",
    "        print(\"Saving results...\")\n",
    "\n",
    "        dict_filename = os.path.join(dir, \"industry_state_dict.pkl\")\n",
    "        with open(dict_filename, 'wb') as f:\n",
    "            pickle.dump(industry_state_dict, f)\n",
    "\n",
    "    return nodes_graph, nodes_industry_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6596f2d7-d5ae-42ad-91ef-c6e8b6263375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up IPUMS Readers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipumspy/readers.py:49: CitationWarning: Use of data from IPUMS is subject to conditions including that users should cite the data appropriately.\n",
      "See the `ipums_conditions` attribute of this codebook for terms of use.\n",
      "See the `ipums_citation` attribute of this codebook for the appropriate citation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ddi_codebook = readers.read_ipums_ddi('data/cps_codebook.xml')\n",
    "iter_microdata = readers.read_microdata_chunked(ddi_codebook, 'data/cps_00001.dat.gz', chunksize=1000)\n",
    "print(\"Set up IPUMS Readers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94a13a5-db35-4383-9b68-2336b965d432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up IPUMS Readers\n",
      "Processing IPUMS data (might take a while)\n",
      "\n",
      "Processed: 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipumspy/readers.py:49: CitationWarning: Use of data from IPUMS is subject to conditions including that users should cite the data appropriately.\n",
      "See the `ipums_conditions` attribute of this codebook for terms of use.\n",
      "See the `ipums_citation` attribute of this codebook for the appropriate citation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 3373000\n",
      "Saving results...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nodes_industry_state_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet up IPUMS Readers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m create_directory_with_timestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_dict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m processed_dict \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miter_microdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved industryXstate map to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(iterator, dir, save)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dict_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     42\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(industry_state_dict, f)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodes_graph, \u001b[43mnodes_industry_state_dict\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nodes_industry_state_dict' is not defined"
     ]
    }
   ],
   "source": [
    "ddi_codebook = readers.read_ipums_ddi('data/ipums_codebook.xml')\n",
    "iter_microdata = readers.read_microdata_chunked(ddi_codebook, 'data/ipums.dat.gz', chunksize=1000)\n",
    "print(\"Set up IPUMS Readers\")\n",
    "\n",
    "dir = create_directory_with_timestamp('processed_dict')\n",
    "processed_dict = process_data(iter_microdata, dir, save=True)\n",
    "print(f\"Saved industryXstate map to {dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763a243-f37f-4472-a14a-115da83afefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a150241-9281-4ea7-942d-007c6a4bb693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acde1ff-a28c-47ab-a70c-746148740b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old loading process: loads directly into a graph, using ACS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca3155-13e1-490d-91a6-05b782f100fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_VARS = ['YEAR', 'SAMPLE', 'SERIAL', 'CBSERIAL', 'HHWT', 'CLUSTER', 'STRATA', 'GQ', 'PERNUM', 'PERWT'] \n",
    "WEALTH_PROXIES = ['INCINVST', 'INCBUS00']\n",
    "INCOMES = ['INCWAGE', 'INCBUS00', 'INCSS', 'INCWELFR', 'INCINVST', 'INCRETIR', 'INCSUPP', 'INCOTHER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89ea31c3-423d-41c9-9ed8-2057cb5dda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_with_timestamp(descriptor='graph'):\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    directory_name = f\"graphs/{descriptor}_{timestamp}\"\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "    return directory_name\n",
    "\n",
    "\n",
    "def add_to_data_graph(df, graph, industry_state_dict):\n",
    "    nodes = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['AGE'] >= 18:    #otherwise lots of n/a values\n",
    "            node_id = str(row['SERIAL']) + '-' + str(row['PERNUM'])\n",
    "            industry_state = str(row['STATEICP']) + '-' + str(row['IND'])\n",
    "            wealth_proxy = row[WEALTH_PROXIES].sum()\n",
    "            node_attributes = row.drop(DEFAULT_VARS).to_dict()\n",
    "            node_attributes['wealth_proxy'] = wealth_proxy\n",
    "            node_attributes['state_x_industry'] = industry_state\n",
    "\n",
    "            nodes.append((node_id, node_attributes))\n",
    "            industry_state_dict[industry_state].append(node_id)\n",
    "\n",
    "    graph.add_nodes_from(nodes)\n",
    "    return graph, industry_state_dict\n",
    "\n",
    "\n",
    "def process_data(iterator, dir, save=False):\n",
    "    print(\"Processing IPUMS data (might take a while)\\n\")\n",
    "    nodes_graph = nx.DiGraph()\n",
    "    industry_state_dict = defaultdict(list)\n",
    "    i = 0\n",
    "    for df_chunk in iterator: \n",
    "        print(f\"\\rProcessed: {i * 1000}\", end='', flush=True)\n",
    "        nodes_graph, nodes_industry_state_dict = add_to_data_graph(df_chunk, nodes_graph, industry_state_dict)\n",
    "        i += 1\n",
    "\n",
    "    print()\n",
    "    \n",
    "    if save:\n",
    "        print(\"Saving results...\")\n",
    "\n",
    "        filename = os.path.join(dir, \"nodes_graph.pkl\")\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(nodes_graph, f)\n",
    "\n",
    "        dict_filename = os.path.join(dir, \"industry_state_dict.pkl\")\n",
    "        with open(dict_filename, 'wb') as f:\n",
    "            pickle.dump(nodes_industry_state_dict, f)\n",
    "\n",
    "    return nodes_graph, nodes_industry_state_dict\n",
    "\n",
    "\n",
    "def collect_edges(graph, industry_state_dict, incl_weight_if_0 = False):\n",
    "    edges_dict = defaultdict(list)\n",
    "    total_industries = len(industry_state_dict)\n",
    "    count = 1\n",
    "\n",
    "    for industry_x_state, nodes in industry_state_dict.items():\n",
    "        print(f\"\\rCollecting edges: {count}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        if len(nodes) > 1:\n",
    "            nodes_data = [(node, graph.nodes[node]['wealth_proxy']) for node in nodes]\n",
    "            nodes_data.sort(key=lambda x: x[1], reverse=True)\n",
    "            for i in range(len(nodes_data) - 1):\n",
    "                u, wealth_u = nodes_data[i]\n",
    "                for j in range(i + 1, len(nodes_data)):\n",
    "                    v, wealth_v = nodes_data[j]\n",
    "                    weight = wealth_u - wealth_v\n",
    "\n",
    "                    if weight != 0 or incl_weight_if_0:\n",
    "                        edges_dict[industry_x_state].append((u, v, weight))\n",
    "        count += 1\n",
    "    print()\n",
    "    return edges_dict\n",
    "\n",
    "def construct_graph(nodes_graph, edges_dict):\n",
    "    big_graph = nodes_graph\n",
    "    total_industries = len(edges_dict)\n",
    "    count = 0\n",
    "\n",
    "    for industry_x_state, edges in edges_dict.items():\n",
    "        print(f\"\\rConstructing big graph: {count}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        count += 1\n",
    "        if len(edges) > 1:\n",
    "            big_graph.add_weighted_edges_from(edges)\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "    return big_graph\n",
    "\n",
    "\n",
    "def process_industry(industry_x_state, nodes, graph, incl_weight_if_0):\n",
    "    nodes_data = np.array([(node, float(graph.nodes[node]['wealth_proxy'])) for node in nodes])\n",
    "    if len(nodes_data) > 1:\n",
    "        nodes_data = nodes_data[nodes_data[:, 1].argsort()[::-1]]  # Ensure sorting by float values\n",
    "        for (u, wealth_u), (v, wealth_v) in combinations(nodes_data, 2):\n",
    "            weight = float(wealth_u) - float(wealth_v)\n",
    "            if weight != 0 or incl_weight_if_0:\n",
    "                yield (industry_x_state, u, v, weight)\n",
    "\n",
    "def collect_edges_to_generator(graph, industry_state_dict, incl_weight_if_0=False):\n",
    "    total_industries = len(industry_state_dict)\n",
    "    for i, (industry_x_state, nodes) in enumerate(industry_state_dict.items(), 1):\n",
    "        print(f\"\\rCollecting edges: {i}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        yield from process_industry(industry_x_state, nodes, graph, incl_weight_if_0)\n",
    "    print()\n",
    "\n",
    "def construct_graph_from_generator(nodes_graph, edges_generator):\n",
    "    big_graph = nodes_graph.copy()  # Create a copy to avoid modifying the original graph\n",
    "    \n",
    "    # Group edges by industry_x_state\n",
    "    sorted_edges = sorted(edges_generator, key=itemgetter(0))\n",
    "    grouped_edges = groupby(sorted_edges, key=itemgetter(0))\n",
    "    \n",
    "    total_industries = sum(1 for _ in grouped_edges)  # Count the number of industries\n",
    "    \n",
    "    # Reset the groupby object\n",
    "    grouped_edges = groupby(sorted_edges, key=itemgetter(0))\n",
    "    \n",
    "    for count, (industry_x_state, industry_edges) in enumerate(grouped_edges, 1):\n",
    "        print(f\"\\rConstructing big graph: {count}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        edges = [(u, v, weight) for _, u, v, weight in industry_edges]\n",
    "        if len(edges) > 1:\n",
    "            big_graph.add_weighted_edges_from(edges)\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "def construct_graphs(industry_state_dict, edge_dict, dir, batch_size=10):\n",
    "    total_industries = len(edge_dict)\n",
    "    count = 0\n",
    "\n",
    "    subgraphs_to_save = []\n",
    "    for industry_x_state, edges in edge_dict.items():\n",
    "        print(f\"\\rConstructing graphs: {count}/{total_industries} industry x states processed\", end='', flush=True)\n",
    "        print(len(edges))\n",
    "        print(edges[0])\n",
    "        count += 1\n",
    "        if len(edges) > 1:\n",
    "            nodes = industry_state_dict[industry_x_state]\n",
    "\n",
    "            # Create a new DiGraph for each subgraph\n",
    "            subgraph = nx.DiGraph()\n",
    "            subgraph.add_nodes_from(nodes)\n",
    "            subgraph.add_weighted_edges_from(edges)\n",
    "            subgraphs_to_save.append((subgraph, industry_x_state))\n",
    "\n",
    "            # Save subgraphs in batches\n",
    "            if count % batch_size == 0 or count == total_industries:\n",
    "                save_subgraphs(subgraphs_to_save, dir)\n",
    "                subgraphs_to_save = []  # Reset batch\n",
    "    print(\"\\nDone!\")\n",
    "    return big_graph\n",
    "\n",
    "\n",
    "def save_subgraphs(subgraphs_to_save, dir):\n",
    "    for subgraph, industry_x_state in subgraphs_to_save:\n",
    "        filename = os.path.join(dir, industry_x_state + '.pkl')\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(subgraph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198350f-8e31-43cf-b650-f2b3d91c89ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "462200a5-9000-49ca-8376-24de31006491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARSE IPUMS DATASET FOR NODES AND INDUSTRY X STATE MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ffce2e2-3171-4050-9079-fa47f9116c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipumspy/readers.py:49: CitationWarning: Use of data from IPUMS is subject to conditions including that users should cite the data appropriately.\n",
      "See the `ipums_conditions` attribute of this codebook for terms of use.\n",
      "See the `ipums_citation` attribute of this codebook for the appropriate citation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up IPUMS Readers\n",
      "Processing IPUMS data (might take a while)\n",
      "\n",
      "Processed: 200000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lm/19nvcr8165sg016zr309_t000000gn/T/ipykernel_80527/1329097364.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miter_microdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_microdata_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddi_codebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/ipums.dat.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Set up IPUMS Readers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_directory_with_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'full_graph'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnodes_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_industry_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_microdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved nodes graph and nodes/industryXstate map to {dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lm/19nvcr8165sg016zr309_t000000gn/T/ipykernel_80527/2009833676.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(iterator, dir, save)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mindustry_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdf_chunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\rProcessed: {i * 1000}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mnodes_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_industry_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_to_data_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindustry_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lm/19nvcr8165sg016zr309_t000000gn/T/ipykernel_80527/2009833676.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, graph, industry_state_dict)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AGE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m#otherwise lots of n/a values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SERIAL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PERNUM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mindustry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STATEICP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IND'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mwealth_proxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWEALTH_PROXIES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mnode_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_VARS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mnode_attributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wealth_proxy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwealth_proxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mnode_attributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_x_industry'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindustry_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5233\u001b[0m         \u001b[0mfalcon\u001b[0m  \u001b[0mspeed\u001b[0m     \u001b[0;36m320.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5234\u001b[0m                 \u001b[0mlength\u001b[0m      \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5235\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5236\u001b[0m         \"\"\"\n\u001b[0;32m-> 5237\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5238\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5239\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5240\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4501\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4505\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4537\u001b[0m         \u001b[0maxis_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4538\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4541\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4542\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4543\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis must be a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddi_codebook = readers.read_ipums_ddi('data/ipums_codebook.xml')\n",
    "iter_microdata = readers.read_microdata_chunked(ddi_codebook, 'data/ipums.dat.gz', chunksize=1000)\n",
    "print(\"Set up IPUMS Readers\")\n",
    "\n",
    "dir = create_directory_with_timestamp('full_graph')\n",
    "nodes_graph, nodes_industry_state_dict = process_data(iter_microdata, dir, save=True)\n",
    "print(f\"Saved nodes graph and nodes/industryXstate map to {dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4081af-7ddd-488c-b78b-1010ba1c2854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8203fd-e2ac-4492-ba07-9ec41ab3fe85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a94075-2d84-4035-b930-fa938f57824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD AND COLLECT ALL EDGES (usually infeasible bc of size of dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be188e5-d89a-4b04-a31e-89097f37ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{dir}/nodes_graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    nodes_graph = pickle.load(f)\n",
    "\n",
    "filename = f\"{dir}/nodes_dict.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    nodes_industry_state_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a71e65f-e7e6-4a0e-a9ab-9aaa5494bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges: 1/13044 industry x states processed"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m edges \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_industry_state_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 69\u001b[0m, in \u001b[0;36mcollect_edges\u001b[0;34m(graph, industry_state_dict, incl_weight_if_0)\u001b[0m\n\u001b[1;32m     66\u001b[0m             v, wealth_v \u001b[38;5;241m=\u001b[39m nodes_data[j]\n\u001b[1;32m     67\u001b[0m             weight \u001b[38;5;241m=\u001b[39m wealth_u \u001b[38;5;241m-\u001b[39m wealth_v\n\u001b[0;32m---> 69\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m incl_weight_if_0:\n\u001b[1;32m     70\u001b[0m                 edges_dict[industry_x_state]\u001b[38;5;241m.\u001b[39mappend((u, v, weight))\n\u001b[1;32m     71\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "edges = collect_edges(nodes_graph, nodes_industry_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7899f96-5422-415a-85fe-61efce28424d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bca958-8ad4-4bda-8061-4cbc009761f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02437bdc-fd5d-4183-83a5-4aee756687db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SUBSAMPLE 1% OF NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fda499e-fb35-4129-b807-d98afab8d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_nodes(nodes_graph, nodes_industry_state_dict, sample_fraction=0.01):\n",
    "    print(f\"Subsampling {sample_fraction * 100}% of nodes from the graph...\")\n",
    "    all_nodes = list(nodes_graph.nodes)\n",
    "    \n",
    "    # Subsample 1% of nodes\n",
    "    sample_size = int(len(all_nodes) * sample_fraction)\n",
    "    print(f\"Total nodes: {len(all_nodes)}, Sample size: {sample_size}\")\n",
    "    sampled_nodes = set(random.sample(all_nodes, sample_size))\n",
    "    subsampled_graph = nodes_graph.subgraph(sampled_nodes).copy()\n",
    "    print(\"Subsampling nodes completed.\")\n",
    "\n",
    "    # Create new industry_state_dict with subsampled nodes\n",
    "    print(\"Creating new industry_state_dict with subsampled nodes...\")\n",
    "    subsampled_industry_state_dict = defaultdict(list)\n",
    "    for industry_state, nodes in nodes_industry_state_dict.items():\n",
    "        subsampled_nodes_in_state = [node for node in nodes if node in sampled_nodes]\n",
    "        if subsampled_nodes_in_state:\n",
    "            subsampled_industry_state_dict[industry_state].extend(subsampled_nodes_in_state)\n",
    "    print(\"New industry_state_dict creation completed.\")\n",
    "\n",
    "    return subsampled_graph, subsampled_industry_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4058fe5-9851-4b82-a0db-c766f4da6f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampling 1.0% of nodes from the graph...\n",
      "Total nodes: 2850502, Sample size: 28505\n",
      "Subsampling nodes completed.\n",
      "Creating new industry_state_dict with subsampled nodes...\n",
      "New industry_state_dict creation completed.\n"
     ]
    }
   ],
   "source": [
    "subnodes, subdict = subsample_nodes(nodes_graph, nodes_industry_state_dict)\n",
    "\n",
    "subsample_dir = \"graphs/subsample_1percent\"\n",
    "\n",
    "filename = os.path.join(subsample_dir, \"nodes_graph.pkl\")\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(subnodes, f)\n",
    "\n",
    "filename = os.path.join(subsample_dir, \"nodes_dict.pkl\")\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(subdict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5171f630-5764-4291-922b-707428d716ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_dir = \"graphs/subsample_1percent\"\n",
    "\n",
    "filename = \"graphs/subsample_1percent/nodes_graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    subnodes = pickle.load(f)\n",
    "\n",
    "filename = \"graphs/subsample_1percent/nodes_dict.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    subdict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e069d16-4921-491e-8e07-c33fdd2c85a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges: 3000/5301 industry x states processed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges_dict = collect_edges(subnodes, subdict)\n",
    "\n",
    "print(\"saving edges industryXstate map\")\n",
    "filename = os.path.join(subsample_dir, 'edges_dict.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(edges_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "620235e3-9b7a-4dff-96ec-2e4d79f2bf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing big graph: 1598/1599 industry x states processed\n",
      "Done!\n",
      "Saving graph\n"
     ]
    }
   ],
   "source": [
    "graph = construct_graph(subnodes, edges_dict)\n",
    "\n",
    "print(\"Saving graph\")\n",
    "filename = os.path.join(subsample_dir, 'graph.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f675815-5ede-4e14-8c96-c5472c41198e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231149fa-7fd8-4bdc-a32e-5af19b92cf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae2ad9-afa3-4818-90e2-fb3371e4dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SUBSAMPLE FOR ILLINOIS (still too big to be able to process for me so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f38a90ce-17b0-45eb-b467-45612ac657e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_nodes_by_state(nodes_graph, nodes_industry_state_dict, icp=21):\n",
    "    # Identify nodes with matching STATEICP (default of 21 is the default state)\n",
    "    state_nodes = [node for node, data in nodes_graph.nodes(data=True) if data.get('STATEICP') == icp]\n",
    "    print(f\"Found {len(state_nodes)} nodes with STATEICP matching {icp}\")\n",
    "\n",
    "\n",
    "    # Create a subgraph with only state nodes\n",
    "    subsampled_graph = nodes_graph.subgraph(state_nodes).copy()\n",
    "    total_industries = len(nodes_industry_state_dict)\n",
    "    count = 0\n",
    "    print(\"Created subgraph with state nodes\")\n",
    "    \n",
    "    # Create new industry_state_dict with subsampled nodes\n",
    "    subsampled_industry_state_dict = {\n",
    "        industry_state: nodes for industry_state, nodes in nodes_industry_state_dict.items()\n",
    "        if industry_state.startswith(str(icp) + \"-\")\n",
    "    }\n",
    "\n",
    "    print(\"Created industry_state_dict with subsampled nodes\")\n",
    "    return subsampled_graph, subsampled_industry_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5fe20f0-5f67-46e3-880a-c04f6c08628b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsample_nodes_by_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# subsample nodes graph and nodes industry X state dict\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m subnodes, subdict \u001b[38;5;241m=\u001b[39m \u001b[43msubsample_nodes_by_state\u001b[49m(nodes_graph, nodes_industry_state_dict, icp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m21\u001b[39m)\n\u001b[1;32m      4\u001b[0m subsample_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraphs/subsample_illinois\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving nodes graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subsample_nodes_by_state' is not defined"
     ]
    }
   ],
   "source": [
    "# subsample nodes graph and nodes industry X state dict\n",
    "subnodes, subdict = subsample_nodes_by_state(nodes_graph, nodes_industry_state_dict, icp=21)\n",
    "\n",
    "subsample_dir = \"graphs/subsample_illinois\"\n",
    "\n",
    "print(\"saving nodes graph\")\n",
    "filename = os.path.join(subsample_dir, \"nodes_graph.pkl\")\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(subnodes, f)\n",
    "\n",
    "print(\"saving nodes industry x state dictionary\")\n",
    "filename = os.path.join(subsample_dir, \"nodes_dict.pkl\")\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(subdict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c512c5a-e918-4ca9-a4cc-01377ad47589",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_dir = \"graphs/subsample_illinois\"\n",
    "filename = \"graphs/subsample_illinois/nodes_graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    subnodes = pickle.load(f)\n",
    "\n",
    "filename = \"graphs/subsample_illinois/nodes_dict.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    subdict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331018b-cf11-4bd2-8ba3-b3cc56702f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges: 1/270 industry x states processed"
     ]
    }
   ],
   "source": [
    "edges = collect_edges_to_generator(subnodes, subdict)\n",
    "graph = construct_graph_from_generator(subnodes, edges)\n",
    "\n",
    "print(\"saving graph\")\n",
    "filename = os.path.join(subsample_dir, 'graph.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(graph, f)\n",
    "\n",
    "# print(\"saving edges industryXstate map\")\n",
    "# filename = os.path.join(subsample_dir, 'edges_dict.pkl')\n",
    "# with open(filename, 'wb') as f:\n",
    "#     pickle.dump(edges_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcfce932-2558-4226-89b9-644302feb556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-3:\n",
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_industry' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A child process terminated abruptly, the process pool is not usable anymore",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_graph_from_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medges_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subsample_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 118\u001b[0m, in \u001b[0;36mconstruct_graph_from_generator\u001b[0;34m(nodes_graph, edges_generator)\u001b[0m\n\u001b[1;32m    115\u001b[0m big_graph \u001b[38;5;241m=\u001b[39m nodes_graph\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# Create a copy to avoid modifying the original graph\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Sort the generator by industry_x_state\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m sorted_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medges_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitemgetter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Group edges by industry_x_state\u001b[39;00m\n\u001b[1;32m    121\u001b[0m grouped_edges \u001b[38;5;241m=\u001b[39m groupby(sorted_edges, key\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;241m0\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m, in \u001b[0;36mcollect_edges_to_generator\u001b[0;34m(graph, industry_state_dict, incl_weight_if_0)\u001b[0m\n\u001b[1;32m    101\u001b[0m total_industries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(industry_state_dict)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m--> 104\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(process_industry, industry_x_state, nodes) \n\u001b[1;32m    105\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m industry_x_state, nodes \u001b[38;5;129;01min\u001b[39;00m industry_state_dict\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(futures, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mCollecting edges: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_industries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m industry x states processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    101\u001b[0m total_industries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(industry_state_dict)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m--> 104\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_industry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindustry_x_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    105\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m industry_x_state, nodes \u001b[38;5;129;01min\u001b[39;00m industry_state_dict\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(futures, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mCollecting edges: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_industries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m industry x states processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py:689\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_lock:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken:\n\u001b[0;32m--> 689\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BrokenProcessPool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken)\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_thread:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore"
     ]
    }
   ],
   "source": [
    "edges_dict = collect_edges_to_generator(subnodes, subdict)\n",
    "graph = construct_graph_from_generator(subnodes, edges_dict)\n",
    "\n",
    "print(\"saving graph\")\n",
    "filename = os.path.join(subsample_dir, 'graph.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7ee9720-50b0-47dd-9886-49037f25a54d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medges_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6adf67a-4298-48a0-92b8-65e52fb8737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"graphs/subsample_illinois/graph.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b96070b3-cfb1-4bc9-936d-eba597f42541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b6d17-c05d-4df0-b4df-7180781d75f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13510b64-034a-4746-928e-28cae49d21e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26073036-9e73-43d8-8958-6ba957459d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19947cae-2abc-4914-bef8-aac6cc6b0a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving edges industryXstate map\n"
     ]
    }
   ],
   "source": [
    "# build edges dict from subsample\n",
    "edges_dict = collect_edges(subnodes, subdict)\n",
    "\n",
    "print(\"saving edges industryXstate map\")\n",
    "filename = os.path.join(subsample_dir, 'edges_dict.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(edges_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30639f-1f3f-416a-b986-21f684c5e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "graph = construct_graph(subnodes, edges_dict)\n",
    "\n",
    "print(\"saving graph\")\n",
    "filename = os.path.join(subsample_dir, 'graph.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ee8a4-3678-4cab-8511-17428ced770b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502105f-9f3c-439e-946b-6200095538cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6e92c-ed2e-45bc-a972-7211f7b1c8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a85431-64ea-42bc-ade5-cdbaeb82f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges: 460/13044 industry x states processed"
     ]
    }
   ],
   "source": [
    "edges_dict = collect_edges(nodes_graph, nodes_industry_state_dict)\n",
    "\n",
    "print(\"saving edges industryXstate map\")\n",
    "filename = os.path.join(dir, 'edges_dict.pkl')\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(edges_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acff293-dda1-4b80-b72c-fdc091f79a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28100dd-85d9-4cc9-8b55-79980c30a155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9de6e8-302b-4e58-af69-856d87c1e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RANDOM TESTING STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba8eb83-81ef-45e2-8766-fd679b377b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes_industry_state_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89451281-273f-4fb6-a395-d4ceeadeb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(nodes)for nodes in nodes_industry_state_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b097c7f7-6a6e-475b-b78e-f57b8d160c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01964725-512d-4ad2-8d2b-9974935e8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67018723"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417792f1-7332-4a41-bcfa-064f643c2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_zero_weight_edges(graph):\n",
    "    non_zero_edges = []\n",
    "    for u, v, data in graph.edges(data=True):\n",
    "        if data.get('weight', 0) != 0:\n",
    "            non_zero_edges.append((u, v, data['weight']))\n",
    "    return non_zero_edges\n",
    "\n",
    "# Example usage\n",
    "non_zero_edges = find_non_zero_weight_edges(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61dab7c4-2b4a-4649-a9a7-0ce32e383e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5232078205966413"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_zero_edges)/graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa43f97-e33c-4624-a65f-a6ad9b02d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one at a time stuff/ debugging:\n",
    "\n",
    "graph = nx.DiGraph()\n",
    "industry_state_dict = defaultdict(list)\n",
    "graph, industry_state_dict = add_to_data_graph(first_chunk, graph, industry_state_dict)\n",
    "graph = add_edges(graph, industry_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e2ff700-955a-41b2-b8ff-a90de50510ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     first_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_microdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_chunk[first_chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(first_chunk[first_chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMONTH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipumspy/readers.py:413\u001b[0m, in \u001b[0;36mread_microdata_chunked\u001b[0;34m(ddi, filename, encoding, subset, chunksize, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_microdata_chunked\u001b[39m(\n\u001b[1;32m    372\u001b[0m     ddi: ddi_definitions\u001b[38;5;241m.\u001b[39mCodebook,\n\u001b[1;32m    373\u001b[0m     filename: Optional[fileutils\u001b[38;5;241m.\u001b[39mFileType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    379\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m    380\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    Read in microdata in chunks as specified by the Codebook.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    As these files are often large, you may wish to filter or read in chunks.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m        An iterator of data frames\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _read_microdata(\n\u001b[1;32m    414\u001b[0m         ddi,\n\u001b[1;32m    415\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    416\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    417\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[1;32m    418\u001b[0m         iterator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    419\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    420\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    422\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipumspy/readers.py:167\u001b[0m, in \u001b[0;36m_read_microdata\u001b[0;34m(ddi, filename, encoding, subset, iterator, chunksize, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(name \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWEIGHT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBMIPCTILE\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    166\u001b[0m                 dtype[col] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mFloat64Dtype()\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (_fix_decimal_expansion(df)\u001b[38;5;241m.\u001b[39mastype(dtype) \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m filename\u001b[38;5;241m.\u001b[39msuffixes:\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# convert variables from default numpy_type to corresponding type in dtype.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipumspy/readers.py:167\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(name \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWEIGHT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBMIPCTILE\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    166\u001b[0m                 dtype[col] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mFloat64Dtype()\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (\u001b[43m_fix_decimal_expansion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m filename\u001b[38;5;241m.\u001b[39msuffixes:\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# convert variables from default numpy_type to corresponding type in dtype.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:6221\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6218\u001b[0m dtype_ser \u001b[38;5;241m=\u001b[39m dtype_ser\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   6220\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 6221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (col_name, col) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m   6222\u001b[0m     cdt \u001b[38;5;241m=\u001b[39m dtype_ser\u001b[38;5;241m.\u001b[39miat[i]\n\u001b[1;32m   6223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isna(cdt):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:1323\u001b[0m, in \u001b[0;36mDataFrame.items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_item_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1323\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m k, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:4283\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4279\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4280\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[1;32m   4282\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(item)\n\u001b[0;32m-> 4283\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4285\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   4287\u001b[0m     \u001b[38;5;66;03m# for a chain\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:3730\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3726\u001b[0m \u001b[38;5;66;03m# icol\u001b[39;00m\n\u001b[1;32m   3727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3728\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[i]\n\u001b[0;32m-> 3730\u001b[0m     col_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3731\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_col_values(col_mgr, i)\n\u001b[1;32m   3733\u001b[0m     \u001b[38;5;66;03m# this is a cached value, mark it so\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:1134\u001b[0m, in \u001b[0;36mBlockManager.iget\u001b[0;34m(self, i, track_ref)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;124;03mReturn the data as a SingleBlockManager.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos[i]]\n\u001b[0;32m-> 1134\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblklocs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# shortcut for select a single-dim from a 2-dim BM\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(values)))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/blocks.py:827\u001b[0m, in \u001b[0;36mBlock.iget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Shape:\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miget\u001b[39m(\u001b[38;5;28mself\u001b[39m, i: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;66;03m# In the case where we have a tuple[slice, int], the slice will always\u001b[39;00m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;66;03m#  be slice(None)\u001b[39;00m\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;66;03m# Note: only reached with self.ndim == 2\u001b[39;00m\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;66;03m# Invalid index type \"Union[int, Tuple[int, int], Tuple[slice, int]]\"\u001b[39;00m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# for \"Union[ndarray[Any, Any], ExtensionArray]\"; expected type\u001b[39;00m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;66;03m# \"Union[int, integer[Any]]\"\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[i]  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slice\u001b[39m(\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28mself\u001b[39m, slicer: \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]\n\u001b[1;32m    838\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    first_chunk = next(iter_microdata)\n",
    "    if len(first_chunk[first_chunk['MONTH'] != 3]) > 0:\n",
    "        print(first_chunk[first_chunk['MONTH'] != 3])\n",
    "first_chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b206d968-aade-4136-95a2-bf74b5c303e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CPSID</th>\n",
       "      <th>ASECFLAG</th>\n",
       "      <th>HFLAG</th>\n",
       "      <th>ASECWTH</th>\n",
       "      <th>STATECENSUS</th>\n",
       "      <th>HHINCOME</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>...</th>\n",
       "      <th>INCSURV2</th>\n",
       "      <th>INCDISA1</th>\n",
       "      <th>INCDISA2</th>\n",
       "      <th>INCRET1</th>\n",
       "      <th>INCRET2</th>\n",
       "      <th>INCPEN1</th>\n",
       "      <th>INCPEN2</th>\n",
       "      <th>INCRINT1</th>\n",
       "      <th>INCRINT2</th>\n",
       "      <th>INCCAPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [YEAR, SERIAL, MONTH, CPSID, ASECFLAG, HFLAG, ASECWTH, STATECENSUS, HHINCOME, PERNUM, CPSIDV, CPSIDP, ASECWT, AGE, SEX, RACE, MARST, EMPSTAT, OCC, OCC1950, IND, IND1950, EDUC, FTOTVAL, INCTOT, INCWAGE, INCBUS, INCFARM, INCUNERN, INCSS, INCWELFR, INCGOV, INCIDR, INCALOTH, INCRETIR, INCSSI, INCDRT, INCINT, INCUNEMP, INCWKCOM, INCVET, INCSURV, INCDISAB, INCDIVID, INCRENT, INCEDUC, INCCHILD, INCALIM, INCASIST, INCOTHER, INCRANN, INCPENS, INCLONGJ, OINCBUS, OINCFARM, OINCWAGE, SRCRETI1, SRCRETI2, INCRETI1, INCRETI2, SRCSURV1, SRCSURV2, INCSURV1, INCSURV2, INCDISA1, INCDISA2, INCRET1, INCRET2, INCPEN1, INCPEN2, INCRINT1, INCRINT2, INCCAPG]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 73 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chunk[first_chunk['MONTH'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecdf1ed8-82c6-4278-a243-47ff084b6525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'SERIAL', 'MONTH', 'CPSID', 'ASECFLAG', 'HFLAG', 'ASECWTH',\n",
       "       'STATECENSUS', 'HHINCOME', 'PERNUM', 'CPSIDV', 'CPSIDP', 'ASECWT',\n",
       "       'AGE', 'SEX', 'RACE', 'MARST', 'EMPSTAT', 'OCC', 'OCC1950', 'IND',\n",
       "       'IND1950', 'EDUC', 'FTOTVAL', 'INCTOT', 'INCWAGE', 'INCBUS', 'INCFARM',\n",
       "       'INCUNERN', 'INCSS', 'INCWELFR', 'INCGOV', 'INCIDR', 'INCALOTH',\n",
       "       'INCRETIR', 'INCSSI', 'INCDRT', 'INCINT', 'INCUNEMP', 'INCWKCOM',\n",
       "       'INCVET', 'INCSURV', 'INCDISAB', 'INCDIVID', 'INCRENT', 'INCEDUC',\n",
       "       'INCCHILD', 'INCALIM', 'INCASIST', 'INCOTHER', 'INCRANN', 'INCPENS',\n",
       "       'INCLONGJ', 'OINCBUS', 'OINCFARM', 'OINCWAGE', 'SRCRETI1', 'SRCRETI2',\n",
       "       'INCRETI1', 'INCRETI2', 'SRCSURV1', 'SRCSURV2', 'INCSURV1', 'INCSURV2',\n",
       "       'INCDISA1', 'INCDISA2', 'INCRET1', 'INCRET2', 'INCPEN1', 'INCPEN2',\n",
       "       'INCRINT1', 'INCRINT2', 'INCCAPG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chunk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3d5c7-d125-4fc1-a1a1-4ab218cf7e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
